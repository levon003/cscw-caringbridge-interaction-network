{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Framework for CaringBridge Social Network Analysis\n",
    "This notebook contains the hypothetical code for using multiprocessing to generate files of format\n",
    "\n",
    "1a : <code> (uid, total_ints, first_int, last_int) </code>\n",
    "\n",
    "1b : <code> (uid, total_authored, first_authored, last_authored) </code>\n",
    "\n",
    "\n",
    "and format\n",
    "\n",
    "2 : <code> (from_uid, to_uid, first_int, last_int, gb, amps, replies) </code>\n",
    "\n",
    "Of course, when this works we would want to move it to a script for each task and run it on MSI. Viewing it on notebooks gives it more clarity as to what is happening for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import sys\n",
    "import csv as csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "POISON = \"POISON\" # this is the kill switch for the write process\n",
    "pwd = \"/home/srivbane/shared/caringbridge/data/projects/sna-social-support/csv_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task One\n",
    "Return <code>(uid, total, first, last)</code> for a kind of datatype as passed in to task one of <code>process()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_user(uid_lines, queue, uid):\n",
    "    total_ints = 0\n",
    "    first_int_createdAt = sys.maxsize;\n",
    "    last_int_createdAt = -1\n",
    "    for line in uid_lines:\n",
    "        from_userId, siteId,  to_userId, connectionType, createdAt_str = line.split(\",\")\n",
    "        assert uid ==  int(from_userId), \"{} - {}\".format(uid, from_userId)\n",
    "        total_ints += 1\n",
    "        createdAt = int(createdAt_str)\n",
    "        if createdAt < first_int_createdAt:\n",
    "            first_int_createdAt = createdAt\n",
    "        if createdAt > last_int_createdAt:\n",
    "            last_int_createdAt = createdAt\n",
    "    output_tuple = (uid, total_ints, first_int_createdAt, last_int_createdAt)\n",
    "    queue.put(output_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task Two\n",
    "Return <code>(from_uid, to_uid, first_int, last_int, gb, amps, replies)</code> for a kind of datatype as passed in to task two of <code>process()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_pair(pair_lines, queue, f_uid, t_uid):\n",
    "    amps = 0; jr = 0; gb = 0;\n",
    "    first_int_createdAt = sys.maxsize;\n",
    "    last_int_createdAt = -1\n",
    "    for line in pair_lines:\n",
    "        from_userId, siteId, to_userId, c_type, createdAt_str = line.split(\",\")\n",
    "        assert f_uid == int(from_userId) and t_uid == int(to_userId), \\\n",
    "        \"{} - {}, {} - {}\".format(f_uid, from_userId, t_uid, to_userId)\n",
    "        createdAt = int(createdAt_str)\n",
    "        if (c_type == \"amps\"):\n",
    "            amps += 1\n",
    "        elif (c_type == \"reply\"):\n",
    "            jr += 1\n",
    "        elif (c_type == \"guestbook\"):\n",
    "            gb += 1\n",
    "        if createdAt < first_int_createdAt:\n",
    "            first_int_createdAt = createdAt\n",
    "        if createdAt > last_int_createdAt:\n",
    "            last_int_createdAt = createdAt\n",
    "    output_tuple = (f_uid, t_uid, first_int_createdAt, last_int_createdAt, gb, amps, jr)\n",
    "    queue.put(output_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Queue/Process\n",
    "Waits for results in the queue and writes them to the outfile as specified in <code>process()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriterProcess(mp.Process):\n",
    "    \n",
    "    def __init__(self, outfile, queue, **kwargs):\n",
    "        super(WriterProcess, self).__init__()\n",
    "        self.outfile = outfile\n",
    "        self.queue = queue\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def run(self):\n",
    "        with open(self.outfile, 'w', encoding=\"utf-8\") as outfile:\n",
    "            while True:\n",
    "                result = self.queue.get()\n",
    "                if result == POISON:\n",
    "                    break\n",
    "                try:\n",
    "                    uid, ti, fi, li = result\n",
    "                    line = \"{},{},{},{}\\n\".format(uid, ti, fi, li)\n",
    "                    #t_uid, f_uid, fi, li, tg, ta, tr = result\n",
    "                    #line = \"{},{},{},{},{},{},{}\\n\".format(t_uid, f_uid, fi, li, tg, ta, tr)\n",
    "                    outfile.write(line)\n",
    "                except mp.TimeoutError:\n",
    "                    sys.stderr.write(\"Process caused a timeout in mp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(inpath, outpath, max_res = None, line_lim = None):\n",
    "    with mp.Pool(processes=24) as pool:\n",
    "        results = []\n",
    "        manager = mp.Manager()\n",
    "        queue = manager.Queue()\n",
    "        w_process = WriterProcess(outfile=outpath, queue=queue)\n",
    "        w_process.start()\n",
    "        print(\"Processes started.\")\n",
    "        f_uid = -1; t_uid = -1;\n",
    "        with open(inpath, 'r', encoding='utf-8') as infile:\n",
    "            uid_lines = []; pair_lines = [];\n",
    "            for i, line in enumerate(infile):\n",
    "                \n",
    "                \"\"\" Both task one and task two are coded in \"\"\"\n",
    "                \n",
    "                # TASK ONE\n",
    "                tokens = line.split(\",\")\n",
    "                if tokens[0] == \"userId\" or int(tokens[0]) == 0:\n",
    "                    continue\n",
    "                curr_uid = int(tokens[0])\n",
    "                if i % 10000 == 0:\n",
    "                    print(i, f_uid, len(uid_lines))\n",
    "                if f_uid != curr_uid:\n",
    "                    if f_uid != -1:\n",
    "                        result = pool.apply_async(process_user, (uid_lines, queue, f_uid,))\n",
    "                        #Non-mp alternative: process_user(uid_lines, queue, f_uid)\n",
    "                        results.append(result)\n",
    "                    f_uid = curr_uid\n",
    "                    uid_lines = []\n",
    "                uid_lines.append(line)\n",
    "                \n",
    "                \"\"\"\n",
    "                # TASK TWO\n",
    "                tokens = line.split(\",\")\n",
    "                if tokens[0] == \"from_userId\" or int(tokens[0]) == 0 \\\n",
    "                or tokens[2] == \"to_userId\" or int(tokens[2]) == 0:\n",
    "                    continue\n",
    "                curr_fuid = int(tokens[0])\n",
    "                curr_tuid = int(tokens[2])\n",
    "                if i % 1000 == 1:\n",
    "                    print(i, f_uid, t_uid, len(pair_lines))\n",
    "                if f_uid != curr_fuid or t_uid != curr_tuid:\n",
    "                    if f_uid != -1 and t_uid != -1:\n",
    "                        result = pool.apply_async(process_pair, (pair_lines, queue, f_uid, t_uid,))\n",
    "                        results.append(result)\n",
    "                    f_uid = curr_fuid\n",
    "                    t_uid = curr_tuid\n",
    "                    pair_lines = []\n",
    "                pair_lines.append(line)\n",
    "            \n",
    "                \"\"\"\n",
    "                \"\"\" End of modified code for task description \"\"\"\n",
    "                \n",
    "                if max_res is not None and len(results) == max_res:\n",
    "                    for result in tqdm(results, desc=\"Joining Results [Inner nest]\"):\n",
    "                        result.get()\n",
    "                    results = []\n",
    "                if line_lim is not None and i > line_lim:\n",
    "                    break\n",
    "                    \n",
    "            \"\"\" Change this code for the function being processed \"\"\"\n",
    "            result = pool.apply_async(process_user, (uid_lines, queue, f_uid,))\n",
    "            results.append(result)\n",
    "            \"\"\" End of changed code for the multiprocessing fw\"\"\"\n",
    "                    \n",
    "        for result in tqdm(results, desc=\"Joining Results [Outer nest]\"):\n",
    "            result.get()\n",
    "        \n",
    "        queue.put(POISON)\n",
    "        w_process.join()\n",
    "        manager.shutdown()\n",
    "    print(\"Finished!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit inpath, outpath dependent on process IO\n",
    "Change max_res to change queue wait size and lime_lim to change how long the iterator goes until interrupted (usually for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    inpath = os.path.join(pwd, \"jo.csv\")\n",
    "    outpath = os.path.join(pwd, \"dynamic_auth.csv\") # change based on task\n",
    "    process(inpath, outpath, max_res = 1000000, line_lim = None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
