{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the NetworkX graph and apply Centrality Measures to examine users/sites importance/influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import sqlite3\n",
    "from html.parser import HTMLParser\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import matplotlib\n",
    "import pylab as pl\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/srivbane/shared/caringbridge/data/projects/sna-social-support/csv_data\"\n",
    "assert os.path.exists(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a User->Site map. Format: dict\n",
    "users = pd.read_csv(\"/home/srivbane/shared/caringbridge/data/projects/sna-social-support/csv_data/pcts.csv\")\n",
    "print(len(users))\n",
    "multi_site_count = 0\n",
    "user_site_map = {}\n",
    "for userId, group in users.groupby(by='userId', sort=False):\n",
    "    siteIds = tuple(group.siteId.tolist())\n",
    "    if len(siteIds) > 1:\n",
    "        multi_site_count += 1\n",
    "    user_site_map[userId] = siteIds\n",
    "print(f\"{len(user_site_map.keys())} users mapped to sites. ({multi_site_count} users to multiple sites.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test User->Site map\n",
    "user_site_map[7326018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop users with userId == 0\n",
    "users.drop(users[users.userId == 0].index, inplace=True)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the journal-replies network data file\n",
    "jr = pd.read_csv(os.path.join(data_dir, \"jr.csv\"))\n",
    "len(jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trim to only authors\n",
    "jr.drop(jr[~jr.from_userId.isin(set(users.userId))].index, inplace=True)\n",
    "len(jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Site->User map. Format: dict\n",
    "site_user_map = {}\n",
    "for siteId, group in tqdm(users.groupby(by='siteId', sort=False)):\n",
    "    userIds = tuple(group.userId.tolist())\n",
    "    site_user_map[siteId] = userIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test Site->User map\n",
    "site_user_map[838509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the initial graph. Nodes: users (represented by userId)\n",
    "G = nx.DiGraph()\n",
    "nodes = list(set(jr.from_userId))\n",
    "G.add_nodes_from(nodes)\n",
    "len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of edges (connections) between users (from_userId to to_userId)\n",
    "edges = []\n",
    "for fromUser, siteId in tqdm(jr[['from_userId', 'siteId']].values):\n",
    "    toUsers = site_user_map[siteId]\n",
    "    for toUser in toUsers:\n",
    "        edges.append((fromUser, toUser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edges.sort()\n",
    "edges[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a list of unique edges from the original list of edges and assign weights to each edge \n",
    "unique_edges = []\n",
    "for key, group in itertools.groupby(edges):\n",
    "    edge_weight = sum(1 for item in group)\n",
    "    weighted_edge = (key[0], key[1], {'weight': edge_weight})\n",
    "    unique_edges.append(weighted_edge)\n",
    "\n",
    "assert len(unique_edges) < len(edges)\n",
    "print (len(unique_edges))\n",
    "unique_edges[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add edges to connect the nodes from a list of unique edges\n",
    "G.add_edges_from(unique_edges)\n",
    "len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# G.edges[{from_userId, to_userId}]: get the weight\n",
    "G.edges[{16, 849533}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# largestScc_G: largest strongly connected components subgraph\n",
    "largestScc_G = G.subgraph(sorted(nx.strongly_connected_components(G), key=len, reverse=True)[0])\n",
    "len(largestScc_G), len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test for the correctness of the directed graph: sum(in_degrees) == sum(out_degrees)\n",
    "indegrees = [in_degree for node, in_degree in largestScc_G.in_degree()]\n",
    "outdegrees = [out_degree for node, out_degree in largestScc_G.out_degree()]\n",
    "assert len(indegrees) == len(outdegrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of nodes and their degrees\n",
    "plt.hist([indegrees, outdegrees], log=True, label=[\"In-degree\", \"Out-degree\"], bins=20, range=(1,40))\n",
    "plt.ylabel(\"Node Count\")\n",
    "plt.xlabel(\"Node Degree\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSortedKeys(d): # sort the values in descending order and get the corresponding list of keys\n",
    "    keys = sorted(d, key=d.get)\n",
    "    keys.reverse()\n",
    "    return keys\n",
    "\n",
    "def getSlice(l, n): # slice the list with length n\n",
    "    if n > len(l):\n",
    "        raise Exception('n exceeds list length')\n",
    "    lst = l[:n]\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Measures\n",
    "## 1. PageRank centrality\n",
    "## 2. (In/Out)-Degree centrality\n",
    "## 3. Betweeness centrality\n",
    "## 4. Closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = nx.pagerank(largestScc_G)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_keys = getSortedKeys(pr)\n",
    "pr_slicedKeys = getSlice(pr_keys, 1000)\n",
    "assert len(pr_slicedKeys) == 1000\n",
    "pr_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (In/Out) Degree centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_central = nx.degree_centrality(largestScc_G)\n",
    "deg_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_central_keys = getSortedKeys(deg_central)\n",
    "deg_central_slicedKeys = getSlice(deg_central_keys, 1000)\n",
    "assert len(deg_central_slicedKeys) == 1000\n",
    "deg_central_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indeg_central = nx.in_degree_centrality(largestScc_G)\n",
    "indeg_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indeg_central_keys = getSortedKeys(indeg_central)\n",
    "indeg_central_slicedKeys = getSlice(indeg_central_keys, 1000)\n",
    "assert len(indeg_central_slicedKeys) == 1000\n",
    "indeg_central_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-degree centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdeg_central = nx.out_degree_centrality(largestScc_G)\n",
    "outdeg_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdeg_central_keys = getSortedKeys(outdeg_central)\n",
    "outdeg_central_slicedKeys = getSlice(outdeg_central_keys, 1000)\n",
    "assert len(outdeg_central_slicedKeys) == 1000\n",
    "outdeg_central_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Betweeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "btw_central = nx.betweenness_centrality(largestScc_G)\n",
    "btw_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "btw_central_keys = getSortedKeys(btw_central)\n",
    "btw_central_slicedKeys = getSlice(btw_central_keys, 1000)\n",
    "assert len(btw_central_slicedKeys) == 1000\n",
    "btw_central_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time\n",
    "close_central = nx.closeness_centrality(largestScc_G)\n",
    "close_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "close_central_keys = getSortedKeys(close_central)\n",
    "close_central_slicedKeys = getSlice(close_central_keys, 1000)\n",
    "assert len(close_central_slicedKeys) == 1000\n",
    "close_central_slicedKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getExtremes(n):\n",
    "    common_nodes = set(deg_central_slicedKeys[:n]).intersection(indeg_central_slicedKeys[:n], \n",
    "                                                            outdeg_central_slicedKeys[:n],\n",
    "                                                            btw_central_slicedKeys[:n],\n",
    "                                                            close_central_slicedKeys[:n])\n",
    "    print (\"Number of extreme nodes (users): \", len(common_nodes))\n",
    "    return list(common_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme nodes (users):  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7326018, 4007054, 17508946, 7781298, 4258911, 23274911]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getExtremes(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme nodes (users):  22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2875016,\n",
       " 1030664,\n",
       " 1706251,\n",
       " 4007054,\n",
       " 20270991,\n",
       " 5072794,\n",
       " 23274911,\n",
       " 28523950,\n",
       " 7781298,\n",
       " 23582261,\n",
       " 710846,\n",
       " 7326018,\n",
       " 6065347,\n",
       " 574151,\n",
       " 5731271,\n",
       " 20682957,\n",
       " 17508946,\n",
       " 25423957,\n",
       " 4258911,\n",
       " 16152816,\n",
       " 15246195,\n",
       " 6746237]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getExtremes(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine centrality results into one dataframe\n",
    "df1 = pd.DataFrame.from_dict(deg_central, orient='index')\n",
    "df1 = df1.reset_index()\n",
    "lst1 = list(indeg_central.values())\n",
    "lst2 = list(outdeg_central.values())\n",
    "lst3 = list(btw_central.values())\n",
    "lst4 = list(close_central.values())\n",
    "df1.columns = ['userId', 'degree_centrality']\n",
    "df1['indeg_centrality'] = lst1\n",
    "df1['outdeg_centrality'] = lst2\n",
    "df1['btw_centrality'] = lst3\n",
    "df1['close_centrality'] = lst4\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure the keys align\n",
    "assert indeg_central.keys() == deg_central.keys() == outdeg_central.keys() == btw_central.keys() == close_central.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write to csv file\n",
    "df1.to_csv(\"/home/srivbane/vuong067/CaringBridge/journal-replies-analysis/KhiemV_work/current_work/notebooks/centrality_measures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the list of extreme sites from extreme nodes\n",
    "def convertToSiteList(nodeList):\n",
    "    siteList = [site for node in nodeList for site in user_site_map[node]]\n",
    "    print (\"Number of extreme sites corresponding to extreme nodes/users: \", len(siteList))\n",
    "    return siteList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extreme nodes (users):  6\n",
      "Number of extreme sites corresponding to extreme nodes/users:  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[156877, 88261, 599513, 552325, 983390, 612345]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertToSiteList(getExtremes(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "levon003-conda",
   "language": "python",
   "name": "levon003-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
